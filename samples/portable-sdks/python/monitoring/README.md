# Monitoring Pattern with Azure Durable Task Scheduler

This sample demonstrates the monitoring pattern with the Azure Durable Task Scheduler using the Python SDK. This pattern enables periodic checking of an external system or process until a certain condition is met or a timeout occurs.

## Prerequisites

1. [Python 3.8+](https://www.python.org/downloads/)
2. [Azure CLI](https://docs.microsoft.com/cli/azure/install-azure-cli)
3. [Docker](https://www.docker.com/products/docker-desktop/) (for emulator option)

## Sample Overview

In this sample, the orchestration demonstrates the monitoring pattern by:

1. Periodically checking the status of a simulated external job
2. Updating the orchestration state with the latest status
3. Either completing when the job is done or timing out after a specified period

This pattern is useful for scenarios where you need to track the progress of an external system or process without blocking resources with a continuous connection.

## Configuring the Sample

There are two separate ways to run an example:

- Using the Emulator
- Using a deployed Scheduler and Taskhub

### Running with a Deployed Scheduler and Taskhub Resource

1. To create a taskhub, follow these steps using the Azure CLI commands:

Create a Scheduler:

```bash
az durabletask scheduler create --resource-group --name --location --ip-allowlist "[0.0.0.0/0]" --sku-capacity 1 --sku-name "Dedicated" --tags "{'myattribute':'myvalue'}"
```

Create Your Taskhub:

```bash
az durabletask taskhub create --resource-group <testrg> --scheduler-name <testscheduler> --name <testtaskhub>
```

2. Retrieve the Endpoint for the Scheduler: Locate the taskhub in the Azure portal to find the endpoint.

3. Set the Environment Variables:

Bash:
```bash
export TASKHUB=<taskhubname>
export ENDPOINT=<taskhubEndpoint>
```

Powershell:
```powershell
$env:TASKHUB = "<taskhubname>"
$env:ENDPOINT = "<taskhubEndpoint>"
```

4. Install the Correct Packages:
```bash
pip install -r requirements.txt
```

5. Grant your developer credentials the Durable Task Data Contributor Role.

### Running with the Emulator

The emulator simulates a scheduler and taskhub, packaged into an easy-to-use Docker container. For these steps, it is assumed that you are using port 8080.

1. Install Docker: If it is not already installed.

2. Pull the Docker Image for the Emulator:

```bash
docker pull mcr.microsoft.com/dts/dts-emulator:v0.0.6
```

3. Run the Emulator: Wait a few seconds for the container to be ready.

```bash
docker run --name dtsemulator -d -p 8080:8080 mcr.microsoft.com/dts/dts-emulator:v0.0.4
```

4. Set the Environment Variables:

Bash:
```bash
export TASKHUB=<taskhubname>
export ENDPOINT=http://localhost:8080
```

Powershell:
```powershell
$env:TASKHUB = "<taskhubname>"
$env:ENDPOINT = "http://localhost:8080"
```

5. Edit the Examples: Change the `token_credential` input of both the `DurableTaskSchedulerWorker` and `DurableTaskSchedulerClient` to `None`.

## Running the Sample

Once you have set up either the emulator or deployed scheduler, follow these steps to run the sample:

1. First, activate your Python virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows, use: venv\Scripts\activate
```

2. Install the required packages:
```bash
pip install -r requirements.txt
```

3. Start the worker in a terminal:
```bash
python worker.py
```
You should see output indicating the worker has started and registered the orchestration and activities.

4. In a new terminal (with the virtual environment activated), run the client:
```bash
python client.py [job_id] [polling_interval] [timeout]
```

For example:
```bash
python client.py job-123 5 30
```

Where:
- `job_id` is an optional identifier for the job (defaults to a generated UUID)
- `polling_interval` is the number of seconds between status checks (defaults to 5)
- `timeout` is the maximum number of seconds to monitor before timing out (defaults to 30)

### What Happens When You Run the Sample

When you run the sample:

1. The client creates an orchestration instance to monitor a job with the provided parameters.

2. The worker executes the `monitor_job` orchestration function, which:
   - Sets up initial monitoring parameters (job ID, polling interval, deadline)
   - Enters a loop that periodically checks the job status
   - Each iteration calls the `check_job_status` activity to simulate checking an external system
   - If the job completes or the deadline is reached, the orchestration completes
   - Otherwise, it schedules itself to wake up after the polling interval using `context.create_timer()`

3. The `check_job_status` activity simulates an external job that takes time to complete, with the completion percentage increasing on each check.

4. The client displays the status updates as the orchestration monitors the job until completion or timeout.

This sample demonstrates a pattern for monitoring long-running processes without maintaining a continuous connection, which is useful for tracking asynchronous operations in external systems.

## Sample Explanation

The monitoring pattern is useful for scenarios where you need to track the progress of an external process or system that may take a while to complete. Instead of blocking resources with a continuous connection, this pattern:

1. Checks the status of the external system periodically
2. Sleeps between checks to conserve resources
3. Completes when either the desired condition is met or a timeout occurs

Common use cases include:
- Monitoring asynchronous job status
- Waiting for resource provisioning to complete
- Polling for file creation or changes
- Checking for availability of services or data

In this sample, the orchestration simulates monitoring an external job by periodically checking its status until it completes successfully or reaches the specified timeout.
